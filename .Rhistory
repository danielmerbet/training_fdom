#load GWLF: discharge and DOC
GWLF <- read.csv(paste0(dir, "data/GWLF.csv"), header = T)
GWLF <- GWLF[,2:ncol(GWLF)]
colnames(GWLF) <- c("date", "q_gwlf", "doc_gwlf")
GWLF$date <- as.Date(GWLF$date, "%m/%d/%Y")
drivers <- merge(drivers, GWLF, by="date")
#drivers <- merge(drivers, DOC, by="date")
write.csv(drivers, paste0(dir,"data/drivers.csv"), row.names = F, quote = F)
library(lubridate)
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
#load drivers (meteorology, soil,  streamflow and all possible variables)
drivers <- read.csv(paste0(dir, "data/drivers.csv"))
drivers$date <- as.Date(drivers$date)
#load target variables
tvar <- "fdom" #"doc"#"fdom"
target <- read.csv(paste0(dir ,"data/",tvar,".csv"))
target$date <- as.Date(target$date)
#merge all and add julian day and dummy
data <- merge(drivers, target, by="date")
#data$yday <- yday(data$date)
data$cyday <- cos(yday(data$date)*pi/180)
#data$syday <- sin(yday(data$date)/365)
data$random <- runif(nrow(data))
plot(data$cyday)
data$cyday <- cos(yday(data$date)*pi/180)
data$random <- runif(nrow(data))
View(data)
library(lubridate); library(dplyr)
#soil and meteo data from Open Meteo
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
soil_meteo <- read.csv(paste0(dir, "download/meteo-soil_data.csv"))
soil_meteo$date <- as.Date(soil_meteo$date)
soil_meteo_temp <- aggregate(. ~ date, data=soil_meteo, FUN = function(x) c(mean = mean(x, na.rm = TRUE)))
soil_meteo_temp$precipitation <- NULL
rain_temp <- aggregate(precipitation ~ date, data=soil_meteo, FUN = function(x) c(sum = sum(x, na.rm = TRUE)))
soil_meteo <- merge(soil_meteo_temp, rain_temp, by="date")
names(soil_meteo) <- c("date","t", "rh", "sp", "cc", "pev",
"ws","st7", "st28", "st100","st255",
"sm7", "sm28", "sm100","sm255","tp")
soil_meteo_temp <- NULL
rain_temp <- NULL
write.csv(soil_meteo, paste0(dir, "data/meteo-soil_daily_data.csv"),
row.names = F, quote = F)
#streamflow data from ATL
#stream <- read.csv(paste0(dir, "data/river.csv"), header = F)
#stream <- data.frame(date=as.Date(stream$V1, "%m/%d/%Y"), q=stream$V2)
#Load lake data (GLM output)
glm_out <- read.csv(paste0(dir, "data/lake.csv"))
lake_data <- data.frame(date=as.Date(glm_out$time),
swt=glm_out$Surface.Temp,
v=glm_out$Volume,
lh=glm_out$Daily.Qe,
sh=glm_out$Daily.Qh,
#light=glm_out$Light,
strat=glm_out$Max.dT.dz)
#merge all possible drivers
#drivers <- merge(stream, lake_data, by="date")
#drivers <- merge(drivers, soil_meteo, by="date")
drivers <- merge(lake_data, soil_meteo, by="date")
#load GWLF: discharge and DOC
GWLF <- read.csv(paste0(dir, "data/GWLF.csv"), header = T)
GWLF <- GWLF[,2:ncol(GWLF)]
colnames(GWLF) <- c("date", "q_gwlf", "doc_gwlf")
GWLF$date <- as.Date(GWLF$date, "%m/%d/%Y")
drivers <- merge(drivers, GWLF, by="date")
#load DOC
#DOC <- read.csv("sau/data/DOC_SAU_C1.csv")
#DOC <- data.frame(date=DOC$Fecha, depth=DOC$Depth, doc=DOC$Valor)
#DOC <- subset(DOC, depth==5)
#DOC <- subset(DOC, depth >= 0 & depth <= 5)
#DOC$date <- as.Date(DOC$date)
#drivers <- merge(drivers, DOC, by="date")
write.csv(drivers, paste0(dir,"data/drivers.csv"), row.names = F, quote = F)
library(lubridate)
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
#load drivers (meteorology, soil,  streamflow and all possible variables)
drivers <- read.csv(paste0(dir, "data/drivers.csv"))
drivers$date <- as.Date(drivers$date)
#load target variables
tvar <- "fdom" #"doc"#"fdom"
target <- read.csv(paste0(dir ,"data/",tvar,".csv"))
target$date <- as.Date(target$date)
#merge all and add julian day and dummy
data <- merge(drivers, target, by="date")
data$cyday <- cos(yday(data$date)*pi/180)
data$random <- runif(nrow(data))
#ML Analysis
###############################################################
#Random forest
library(randomForest)
save_rsq <- c()
save_rmse <- c()
#1. TRAINING WITH ALL DATA AND TESTING WITH SAMPLES OOB
#in theory this is wrong because the trianing data is autocorrelated
#train RF
formula <- as.formula(paste(tvar, "~ . - date"))
RFfit <- randomForest(formula, data = data, ntree = 1000)
#testing: check with data not used in training but still autocorrelated (Out-of-Bag data)
predRF<- predict(RFfit) # without data, give the prediction with OOB samples
rsqOOB = round((cor(predRF, data[tvar]))^2,2) ; rsqOOB
rmseOOB <- round(sqrt(mean((data[tvar][,1] - predRF)^2)), 2); rmseOOB
importance_random <- importance(RFfit); importance_random
importance_random/sum(importance_random)*100
plot(data$cyday, data$fdom)
#fdom data correction: temperature effect
#table from manufacturer (YSI)
temp_effect <- c(30, 28, 26, 24, 22, 20, 18, 16, 14, 12, 10, 8)
qsu_effect <- c(289.2, 291.9, 294.6, 297.3, 300, 302.7, 305.4, 308.1, 310.8, 313.8, 316.5, 319.2)
#fdom data correction: temperature effect
#table from manufacturer (YSI)
temp_effect <- c(30, 28, 26, 24, 22, 20, 18, 16, 14, 12, 10, 8)
qsu_effect <- c(289.2, 291.9, 294.6, 297.3, 300, 302.7, 305.4, 308.1, 310.8, 313.8, 316.5, 319.2)
plot(temp_effect, qsu_effect)
library(lubridate)
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
#load drivers (meteorology, soil,  streamflow and all possible variables)
drivers <- read.csv(paste0(dir, "data/drivers.csv"))
drivers$date <- as.Date(drivers$date)
#load target variables
tvar <- "fdom" #"doc"#"fdom"
target <- read.csv(paste0(dir ,"data/",tvar,".csv"))
target$date <- as.Date(target$date)
#merge all and add julian day and dummy
data <- merge(drivers, target, by="date")
data$cyday <- cos(yday(data$date)*pi/180)
data$random <- runif(nrow(data))
plot(data$t, data$fdom)
plot(data$fdom, data$t)
#fdom data correction: temperature effect
#table from manufacturer (YSI)
temp_effect <- c(30, 28, 26, 24, 22, 20, 18, 16, 14, 12, 10, 8)
qsu_effect <- c(289.2, 291.9, 294.6, 297.3, 300, 302.7, 305.4, 308.1, 310.8, 313.8, 316.5, 319.2)
library(lubridate)
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
#load drivers (meteorology, soil,  streamflow and all possible variables)
drivers <- read.csv(paste0(dir, "data/drivers.csv"))
drivers$date <- as.Date(drivers$date)
#load target variables
tvar <- "fdom" #"doc"#"fdom"
target <- read.csv(paste0(dir ,"data/",tvar,".csv"))
target$date <- as.Date(target$date)
#merge all and add julian day and dummy
data <- merge(drivers, target, by="date")
data$cyday <- cos(yday(data$date)*pi/180)
data$random <- runif(nrow(data))
lm(data$fdom ~ data$t)
regression <- lm(data$fdom ~ data$t)
regression$coefficients
reticulate::repl_python()
library(lubridate)
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
#load drivers (meteorology, soil,  streamflow and all possible variables)
drivers <- read.csv(paste0(dir, "data/drivers.csv"))
drivers$date <- as.Date(drivers$date)
#load target variables
tvar <- "fdom" #"doc"#"fdom"
target <- read.csv(paste0(dir ,"data/",tvar,".csv"))
target$date <- as.Date(target$date)
#merge all and add julian day and dummy
data <- merge(drivers, target, by="date")
data$cyday <- cos(yday(data$date)*pi/180)
data$random <- runif(nrow(data))
#ML Analysis
###############################################################
#Random forest
library(randomForest)
save_rsq <- c()
save_rmse <- c()
#1. TRAINING WITH ALL DATA AND TESTING WITH SAMPLES OOB
#in theory this is wrong because the trianing data is autocorrelated
#train RF
formula <- as.formula(paste(tvar, "~ . - date"))
RFfit <- randomForest(formula, data = data, ntree = 1000)
#testing: check with data not used in training but still autocorrelated (Out-of-Bag data)
predRF<- predict(RFfit) # without data, give the prediction with OOB samples
rsqOOB = round((cor(predRF, data[tvar]))^2,2) ; rsqOOB
rmseOOB <- round(sqrt(mean((data[tvar][,1] - predRF)^2)), 2); rmseOOB
importance_random <- importance(RFfit); importance_random
importance_random/sum(importance_random)*100
library(lubridate); library(dplyr)
#soil and meteo data from Open Meteo
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
soil_meteo <- read.csv(paste0(dir, "download/meteo-soil_data.csv"))
soil_meteo$date <- as.Date(soil_meteo$date)
soil_meteo_temp <- aggregate(. ~ date, data=soil_meteo, FUN = function(x) c(mean = mean(x, na.rm = TRUE)))
soil_meteo_temp$precipitation <- NULL
#soil and meteo data from Open Meteo
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
soil_meteo <- read.csv(paste0(dir, "download/meteo-soil_data.csv"))
View(soil_meteo)
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
soil_meteo <- read.csv(paste0(dir, "download/meteo-soil_data.csv"))
soil_meteo$date <- as.Date(soil_meteo$date)
soil_meteo_temp <- aggregate(. ~ date, data=soil_meteo, FUN = function(x) c(mean = mean(x, na.rm = TRUE)))
View(soil_meteo_temp)
View(soil_meteo)
#soil and meteo data from Open Meteo
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
soil_meteo <- read.csv(paste0(dir, "download/meteo-soil_data.csv"))
View(soil_meteo)
#soil and meteo data from Open Meteo
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
soil_meteo <- read.csv(paste0(dir, "download/meteo-soil_data.csv"))
soil_meteo$date <- as.Date(soil_meteo$date)
soil_meteo_temp <- aggregate(. ~ date, data=soil_meteo, FUN = function(x) c(mean = mean(x, na.rm = TRUE)))
soil_meteo_temp$precipitation <- NULL
rain_temp <- aggregate(precipitation ~ date, data=soil_meteo, FUN = function(x) c(sum = sum(x, na.rm = TRUE)))
soil_meteo_temp$et0_fao_evapotranspiration <- NULL
etp_temp <- aggregate(et0_fao_evapotranspiration ~ date, data=soil_meteo, FUN = function(x) c(sum = sum(x, na.rm = TRUE)))
soil_meteo <- merge(soil_meteo_temp, rain_temp, by="date")
soil_meteo <- merge(soil_meteo, etp_temp, by="date")
names(soil_meteo) <- c("date","t", "rh", "sp", "cc", "ws",
"sr", "st7", "st28", "st100","st255",
"sm7", "sm28", "sm100","sm255",
"tp", "pev")
soil_meteo_temp <- NULL
rain_temp <- NULL
etp_temp <- NULL
write.csv(soil_meteo, paste0(dir, "data/meteo-soil_daily_data.csv"),
row.names = F, quote = F)
#Load lake data (GLM output)
glm_out <- read.csv(paste0(dir, "data/lake.csv"))
lake_data <- data.frame(date=as.Date(glm_out$time),
swt=glm_out$Surface.Temp,
v=glm_out$Volume,
lh=glm_out$Daily.Qe,
sh=glm_out$Daily.Qh,
#light=glm_out$Light,
strat=glm_out$Max.dT.dz)
#merge all possible drivers
#drivers <- merge(stream, lake_data, by="date")
#drivers <- merge(drivers, soil_meteo, by="date")
drivers <- merge(lake_data, soil_meteo, by="date")
#load GWLF: discharge and DOC
GWLF <- read.csv(paste0(dir, "data/GWLF.csv"), header = T)
GWLF <- GWLF[,2:ncol(GWLF)]
colnames(GWLF) <- c("date", "q_gwlf", "doc_gwlf")
GWLF$date <- as.Date(GWLF$date, "%m/%d/%Y")
drivers <- merge(drivers, GWLF, by="date")
#drivers <- merge(drivers, DOC, by="date")
write.csv(drivers, paste0(dir,"data/drivers.csv"), row.names = F, quote = F)
library(lubridate)
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
#load drivers (meteorology, soil,  streamflow and all possible variables)
drivers <- read.csv(paste0(dir, "data/drivers.csv"))
drivers$date <- as.Date(drivers$date)
#load target variables
tvar <- "fdom" #"doc"#"fdom"
target <- read.csv(paste0(dir ,"data/",tvar,".csv"))
target$date <- as.Date(target$date)
#merge all and add julian day and dummy
data <- merge(drivers, target, by="date")
data$cyday <- cos(yday(data$date)*pi/180)
data$random <- runif(nrow(data))
View(data)
#ML Analysis
###############################################################
#Random forest
library(randomForest)
save_rsq <- c()
save_rmse <- c()
#1. TRAINING WITH ALL DATA AND TESTING WITH SAMPLES OOB
#in theory this is wrong because the trianing data is autocorrelated
#train RF
formula <- as.formula(paste(tvar, "~ . - date"))
RFfit <- randomForest(formula, data = data, ntree = 1000)
#testing: check with data not used in training but still autocorrelated (Out-of-Bag data)
predRF<- predict(RFfit) # without data, give the prediction with OOB samples
rsqOOB = round((cor(predRF, data[tvar]))^2,2) ; rsqOOB
rmseOOB <- round(sqrt(mean((data[tvar][,1] - predRF)^2)), 2); rmseOOB
importance_random <- importance(RFfit); importance_random
importance_random/sum(importance_random)*100
plot(data$sm255)
plot(data$cyday, data$sm255)
#fdom data correction: temperature effect
#table from manufacturer (YSI)
temp_effect <- c(30, 28, 26, 24, 22, 20, 18, 16, 14, 12, 10, 8)
qsu_effect <- c(289.2, 291.9, 294.6, 297.3, 300, 302.7, 305.4, 308.1, 310.8, 313.8, 316.5, 319.2)
library(lubridate)
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
#load drivers (meteorology, soil,  streamflow and all possible variables)
drivers <- read.csv(paste0(dir, "data/drivers.csv"))
drivers$date <- as.Date(drivers$date)
#load target variables
tvar <- "fdom" #"doc"#"fdom"
target <- read.csv(paste0(dir ,"data/",tvar,".csv"))
target$date <- as.Date(target$date)
#merge all and add julian day and dummy
data <- merge(drivers, target, by="date")
data$cyday <- cos(yday(data$date)*pi/180)
data$random <- runif(nrow(data))
regression <- lm(data$fdom ~ data$t)
regression$coeficients
regression$coefficients
plot(regression)
plot(data$t, data$fdom)
regression <- lm(temp_effect ~ qsu_effect)
plot(regression)
plot(temp_effect, qsu_effect)
regression$coefficients
#fdom data correction: temperature effect
#table from manufacturer (YSI)
temp_effect <- c(30, 28, 26, 24, 22, 20, 18, 16, 14, 12, 10, 8)
qsu_effect <- c(289.2, 291.9, 294.6, 297.3, 300, 302.7, 305.4, 308.1, 310.8, 313.8, 316.5, 319.2)
library(lubridate)
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
#load drivers (meteorology, soil,  streamflow and all possible variables)
drivers <- read.csv(paste0(dir, "data/drivers.csv"))
drivers$date <- as.Date(drivers$date)
#load target variables
tvar <- "fdom" #"doc"#"fdom"
target <- read.csv(paste0(dir ,"data/",tvar,".csv"))
target$date <- as.Date(target$date)
#merge all
data <- merge(drivers, target, by="date")
regression <- lm(temp_effect ~ qsu_effect)
regression$coefficients
plot(temp_effect, qsu_effect,
pch = 16, col = "blue",
xlab = "Temperature Effect",
ylab = "QSU Effect")
abline(model, col = "red", lwd = 2)
abline(regressionl, col = "red", lwd = 2)
abline(regression, col = "red", lwd = 2)
regression <- lm(temp_effect ~ qsu_effect)
regression$coefficients
regression <- lm(qsu_effect ~ temp_effect)
regression$coefficients
plot(temp_effect, qsu_effect,
pch = 16, col = "blue",
xlab = "Temperature Effect",
ylab = "QSU Effect")
abline(regression, col = "red", lwd = 2)
regression$coefficients
regression$coefficients[2]
slope_effect <- regression$coefficients[2]
#set regresion own data by using maufacturer slope
#intercept must be found
plot(data$swt, data$fdom,
xlab = "SWT",
#set regresion own data by using maufacturer slope
#intercept must be found
plot(data$swt, data$fdom,
#set regresion own data by using maufacturer slope
#intercept must be found
plot(data$swt, data$fdom,
pch = 16, col = "blue",
xlab = "SWT",
ylab = "fDOM")
slope_effect
data$swt
data[c("fdom")]
data[c("swt","fdom")]
data <- data[c("swt","fdom")]
View(data)
regression <- lm(data$fdom ~ data$swt)
abline(regression, col = "red", lwd = 2)
regression$coefficients
slope_effect
data
(data$swt-22)*slope_effect
data$fdom_cor <- (data$swt-22)*slope_effect + data$fdom
#correct fdom: 22 degrees correspond to 300 QSU
data$fdom_cor <- (data$swt-22)*slope_effect + data$fdom
#set regresion own data by using maufacturer slope
#intercept must be found
plot(data$swt, data$fdom,
pch = 16, col = "blue",
xlab = "SWT",
ylab = "fDOM")
#correct fdom: 22 degrees correspond to 300 QSU
data$fdom_cor <- (data$swt-22)*slope_effect + data$fdom
#correct fdom: 22 degrees correspond to 300 QSU
data$fdom_cor <- (data$swt-22)*slope_effect + data$fdom
points(data$swt, data$fdom_cor, col="red")
#set regresion own data by using maufacturer slope
#intercept must be found
plot(data$swt, data$fdom,
pch = 16, col = "blue",
xlab = "SWT",
ylab = "fDOM", ylim=c(0, 70))
points(data$swt, data$fdom_cor, col="red")
#set regresion own data by using maufacturer slope
#intercept must be found
plot(data$swt, data$fdom,
pch = 16, col = "blue",
xlab = "SWT",
ylab = "fDOM", ylim=c(0, 90))
#correct fdom: 22 degrees correspond to 300 QSU
data$fdom_cor <- (data$swt-22)*slope_effect + data$fdom
points(data$swt, data$fdom_cor, col="red")
plot(data$fdom)
ponts(data$fdom_cor, col="red")
points(data$fdom_cor, col="red")
plot(data$fdom, ylim=c(0,80))
points(data$fdom_cor, col="red")
#set regresion own data by using maufacturer slope
#intercept must be found
plot(data$swt, data$fdom,
pch = 16, col = "blue",
xlab = "SWT",
ylab = "fDOM", ylim=c(0, 90))
#correct fdom: 22 degrees correspond to 300 QSU
data$fdom_cor <- (data$swt-22)*slope_effect + data$fdom
points(data$swt, data$fdom_cor, col="red")
plot(data$fdom, ylim=c(0,80))
points(data$fdom_cor, col="red")
#set regresion own data by using maufacturer slope
#intercept must be found
plot(data$swt, data$fdom,
pch = 16, col = "blue",
xlab = "SWT",
ylab = "fDOM", ylim=c(0, 90))
#correct fdom: 22 degrees correspond to 300 QSU
data$fdom_cor <- (data$swt-22)*slope_effect + data$fdom
points(data$swt, data$fdom_cor, col="red")
plot(data$fdom, ylim=c(0,80))
points(data$fdom_cor, col="red")
View(data)
reticulate::repl_python()
library(lubridate); library(dplyr)
#soil and meteo data from Open Meteo
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
soil_meteo <- read.csv(paste0(dir, "download/meteo-soil_data.csv"))
soil_meteo$date <- as.Date(soil_meteo$date)
soil_meteo_temp <- aggregate(. ~ date, data=soil_meteo, FUN = function(x) c(mean = mean(x, na.rm = TRUE)))
soil_meteo_temp$precipitation <- NULL
rain_temp <- aggregate(precipitation ~ date, data=soil_meteo, FUN = function(x) c(sum = sum(x, na.rm = TRUE)))
soil_meteo_temp$et0_fao_evapotranspiration <- NULL
etp_temp <- aggregate(et0_fao_evapotranspiration ~ date, data=soil_meteo, FUN = function(x) c(sum = sum(x, na.rm = TRUE)))
soil_meteo <- merge(soil_meteo_temp, rain_temp, by="date")
soil_meteo <- merge(soil_meteo, etp_temp, by="date")
names(soil_meteo) <- c("date","t", "rh", "sp", "cc", "ws",
"sr", "st7", "st28", "st100","st255",
"sm7", "sm28", "sm100","sm255",
"tp", "pev")
soil_meteo_temp <- NULL
rain_temp <- NULL
etp_temp <- NULL
write.csv(soil_meteo, paste0(dir, "data/meteo-soil_daily_data.csv"),
row.names = F, quote = F)
#Load lake data (GLM output)
glm_out <- read.csv(paste0(dir, "data/lake.csv"))
lake_data <- data.frame(date=as.Date(glm_out$time),
swt=glm_out$Surface.Temp,
v=glm_out$Volume,
lh=glm_out$Daily.Qe,
sh=glm_out$Daily.Qh,
#light=glm_out$Light,
strat=glm_out$Max.dT.dz)
#merge all possible drivers
#drivers <- merge(stream, lake_data, by="date")
#drivers <- merge(drivers, soil_meteo, by="date")
drivers <- merge(lake_data, soil_meteo, by="date")
#load GWLF: discharge and DOC
GWLF <- read.csv(paste0(dir, "data/GWLF.csv"), header = T)
GWLF <- GWLF[,2:ncol(GWLF)]
colnames(GWLF) <- c("date", "q_gwlf", "doc_gwlf")
GWLF$date <- as.Date(GWLF$date, "%m/%d/%Y")
drivers <- merge(drivers, GWLF, by="date")
#drivers <- merge(drivers, DOC, by="date")
write.csv(drivers, paste0(dir,"data/drivers.csv"), row.names = F, quote = F)
library(lubridate)
case_study <- "sau"
dir <- paste0("~/Documents/intoDBP/training_fdom/",case_study, "/")
#load drivers (meteorology, soil,  streamflow and all possible variables)
drivers <- read.csv(paste0(dir, "data/drivers.csv"))
drivers$date <- as.Date(drivers$date)
#load target variables
tvar <- "fdom" #"doc"#"fdom"
target <- read.csv(paste0(dir ,"data/",tvar,".csv"))
target$date <- as.Date(target$date)
#merge all and add julian day and dummy
data <- merge(drivers, target, by="date")
data$cyday <- cos(yday(data$date)*pi/180)
data$random <- runif(nrow(data))
#ML Analysis
###############################################################
#Random forest
library(randomForest)
save_rsq <- c()
save_rmse <- c()
#1. TRAINING WITH ALL DATA AND TESTING WITH SAMPLES OOB
#in theory this is wrong because the trianing data is autocorrelated
#train RF
formula <- as.formula(paste(tvar, "~ . - date"))
RFfit <- randomForest(formula, data = data, ntree = 1000)
#testing: check with data not used in training but still autocorrelated (Out-of-Bag data)
predRF<- predict(RFfit) # without data, give the prediction with OOB samples
rsqOOB = round((cor(predRF, data[tvar]))^2,2) ; rsqOOB
rmseOOB <- round(sqrt(mean((data[tvar][,1] - predRF)^2)), 2); rmseOOB
importance_random <- importance(RFfit); importance_random
importance_random/sum(importance_random)*100
View(drivers)
plot(data$st28)
plot(data$st28, data$cyday)
(data$swt-22)*slope_effect
reticulate::repl_python()
